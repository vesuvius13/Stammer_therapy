# Stammering Assistant - Visual Feedback

A browser-based tool to assist with stammering therapy using visual feedback and speech recognition.

## Features
- **Visual Block Detection**: Uses camera (FaceMesh) to detect open mouth blocks and pressed lips blocks.
- **Repetition Detection**: Detects word and sound repetitions (e.g., "t-t-time").
- **Secondary Behaviors**: Monitors rapid eye blinking and facial tension.
- **Breathing Guide**: Visual breathing exercises triggered when stammering is detected.
- **Live Transcription**: Real-time speech-to-text feedback.

## Modes of Use
At the bottom of the screen, you can toggle between two practice modes:

### 1. **Freestyle Mode (Default)**
For open-ended speaking practice.
1. Allow camera and microphone access.
2. Click **Start**.
3. Speak naturally. The assistant will analyze your speech and facial movements.
4. Follow the on-screen alerts and breathing guides if a block or stutter is detected.

### 2. **Interview Mode**

The application includes an **Interview Mode** that monitors your speech while you answer job-specific questions generated by an AI. There are two versions of this depending on your setup:

### 1. Web Version (`index.html`) - via GitHub Pages
This is the default version designed to be hosted online (e.g., via GitHub Pages). It uses the **OpenAI API** to generate questions.
*   **Setup**: No local server is required. Open the hosted link.
*   **Usage**: Click **Interview**, enter the job position, and provide your **OpenAI API Key**.
*   **Models**: Select your preferred `gpt` model and click **Start Interview**.

### 2. Local Version (`stammer_therapy_local.html`) - via Ollama
This version uses a local [Ollama](https://ollama.com/) instance to generate questions, keeping everything running entirely on your machine.

**Prerequisites:**
1. **Python 3**: For running a local web server (needed to bypass browser CORS policies).
2. **Ollama**: Download and install from [ollama.com](https://ollama.com/).
3. **Ollama Models**: Pull at least one model (e.g., `ollama pull llama3`).

**How to Run:**
1. Start Ollama and ensure your terminal is running:
   ```bash
   ollama serve
   ```
2. Open a *new* terminal window in the project folder and start a local web server:
   ```bash
   python3 -m http.server 8000
   ```
3. Open [http://localhost:8000/stammer_therapy_local.html](http://localhost:8000/stammer_therapy_local.html) in your browser.

## Privacy
All processing for block and stutter detection is done **locally** in your browser using MediaPipe and Web Speech API. 
* If using the **Web Version** (`index.html`), the text prompt (job title) is sent to OpenAI to generate questions.
* If using the **Local Version** (`stammer_therapy_local.html`), no interview data is sent to the cloud.
No video or audio data is ever stored or transmitted.
